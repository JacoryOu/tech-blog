---
title: "智能体记忆管理：从短期到长期"
date: 2026-02-08 08:00:20
author: "小欧Jacory"
category: "AI"
tags: ["AI Agents", "Memory", "架构设计"]
readTime: 20
cover: ""
excerpt: "探索AI智能体的记忆机制，学习如何实现短期上下文记忆和长期知识存储，构建具备持续学习能力的智能体。"
featured: false
---

## 目录

- [为什么需要记忆](#为什么需要记忆)
- [记忆类型：短期vs长期](#记忆类型短期vs长期)
- [短期记忆实现](#短期记忆实现)
- [长期记忆：数据库存储](#长期记忆数据库存储)
- [记忆压缩策略](#记忆压缩策略)
- [实操案例：个人助理记忆系统](#实操案例个人助理记忆系统)
- [隐私保护](#隐私保护)
- [总结](#总结)

## 正文

### 1. 为什么需要记忆

AI智能体（AI Agent）与传统的大语言模型最大的区别之一就是**记忆能力**。没有记忆的智能体就像一个"金鱼"——每次对话都是全新的开始，无法记住用户的偏好、历史对话内容，更无法随着时间推移不断学习和改进。

**记忆带来的核心价值：**

- **个性化体验**：记住用户的名字、喜好、工作习惯
- **上下文连贯性**：跨会话保持对话的连贯性
- **知识积累**：从每次交互中学习，越用越聪明
- **任务状态追踪**：长期任务的进度和状态管理

举个简单例子：一个日程管理助手，如果没有记忆，每次你都要重新告诉它"我是程序员，下午2点有站会"；而有记忆的助手会记住你的工作节奏，自动在合适的时间提醒你。

### 2. 记忆类型：短期vs长期

智能体的记忆通常分为两大类：

#### 短期记忆（Short-term Memory / Working Memory）

短期记忆保存的是**当前会话**的上下文信息，包括：
- 当前对话的历史消息
- 正在进行的任务状态
- 临时计算结果

**特点**：
- 生命周期：一个会话（session）
- 存储方式：内存（RAM）
- 访问速度：极快（毫秒级）
- 容量限制：受限于模型上下文窗口

#### 长期记忆（Long-term Memory）

长期记忆保存的是**跨会话**的持久化信息，包括：
- 用户画像和偏好
- 历史对话摘要
- 学习到的知识和规则
- 任务执行的历史记录

**特点**：
- 生命周期：永久（直到被删除）
- 存储方式：数据库、文件系统
- 访问速度：较慢（需要IO操作）
- 容量：理论上无限

### 3. 短期记忆实现

短期记忆通常通过**提示工程（Prompt Engineering）**来实现。最直接的方式就是将历史对话作为上下文传递给模型。

#### 基础实现

```python
class ShortTermMemory:
    def __init__(self, max_messages=10):
        self.messages = []
        self.max_messages = max_messages
    
    def add_message(self, role, content):
        """添加消息到记忆"""
        self.messages.append({"role": role, "content": content})
        # 保持记忆在限制范围内
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages:]
    
    def get_context(self):
        """获取用于提示的上下文"""
        return self.messages
    
    def clear(self):
        """清空记忆"""
        self.messages = []
```

#### 上下文窗口管理

大语言模型都有**上下文长度限制**（如GPT-4是128K tokens，Claude 3.5是200K tokens）。当对话过长时，需要智能地管理上下文：

**策略1：滑动窗口**
```python
def trim_messages(messages, max_tokens=8000):
    """保留最近的消息，丢弃旧的"""
    total = 0
    trimmed = []
    for msg in reversed(messages):
        tokens = estimate_tokens(msg['content'])
        if total + tokens > max_tokens:
            break
        total += tokens
        trimmed.insert(0, msg)
    return trimmed
```

**策略2：摘要压缩**
当历史消息太多时，可以用模型本身生成摘要：

```python
async def summarize_old_messages(messages):
    """将旧消息压缩成摘要"""
    summary_prompt = f"""
    请总结以下对话的关键信息，保留重要的事实和决策：
    {format_messages(messages)}
    """
    summary = await llm.generate(summary_prompt)
    return {"role": "system", "content": f"历史摘要：{summary}"}
```

### 4. 长期记忆：数据库存储

长期记忆需要持久化存储，常用的方案包括：

#### 方案1：关系型数据库（SQLite/PostgreSQL）

适合存储结构化数据，如用户信息、配置等。

```python
import sqlite3

class LongTermMemory:
    def __init__(self, db_path="memory.db"):
        self.conn = sqlite3.connect(db_path)
        self._init_tables()
    
    def _init_tables(self):
        """初始化记忆表"""
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS user_preferences (
                user_id TEXT PRIMARY KEY,
                preferences TEXT,  -- JSON格式
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS conversation_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT,
                session_id TEXT,
                summary TEXT,
                key_facts TEXT,  -- JSON格式
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        self.conn.commit()
    
    def save_preference(self, user_id, key, value):
        """保存用户偏好"""
        import json
        cursor = self.conn.execute(
            "SELECT preferences FROM user_preferences WHERE user_id = ?",
            (user_id,)
        )
        row = cursor.fetchone()
        
        if row:
            prefs = json.loads(row[0])
            prefs[key] = value
            self.conn.execute(
                "UPDATE user_preferences SET preferences = ?, updated_at = CURRENT_TIMESTAMP WHERE user_id = ?",
                (json.dumps(prefs), user_id)
            )
        else:
            self.conn.execute(
                "INSERT INTO user_preferences (user_id, preferences) VALUES (?, ?)",
                (user_id, json.dumps({key: value}))
            )
        self.conn.commit()
    
    def get_preference(self, user_id, key=None):
        """获取用户偏好"""
        import json
        cursor = self.conn.execute(
            "SELECT preferences FROM user_preferences WHERE user_id = ?",
            (user_id,)
        )
        row = cursor.fetchone()
        if not row:
            return None
        prefs = json.loads(row[0])
        return prefs.get(key) if key else prefs
```

#### 方案2：向量数据库（Chroma/Pinecone）

适合存储语义化记忆，支持基于相似度的检索。

```python
import chromadb
from chromadb.utils import embedding_functions

class VectorMemory:
    def __init__(self, collection_name="memories"):
        self.client = chromadb.PersistentClient(path="./chroma_db")
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()
        
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_fn
        )
    
    def add_memory(self, user_id, content, memory_type="fact"):
        """添加记忆"""
        import uuid
        memory_id = str(uuid.uuid4())
        
        self.collection.add(
            documents=[content],
            metadatas=[{"user_id": user_id, "type": memory_type}],
            ids=[memory_id]
        )
        return memory_id
    
    def search_relevant_memories(self, user_id, query, n_results=5):
        """检索相关记忆"""
        results = self.collection.query(
            query_texts=[query],
            where={"user_id": user_id},
            n_results=n_results
        )
        return results['documents'][0]
```

### 5. 记忆压缩策略

随着时间推移，记忆数据会越来越多，需要有效的压缩和管理策略：

#### 层次化记忆架构

```
L1 - 工作记忆（当前会话）
    ↓ 会话结束
L2 - 短期摘要（最近N个会话的摘要）
    ↓ 定期归档
L3 - 长期知识（提取的关键事实和模式）
    ↓ 定期总结
L4 - 核心画像（用户的核心偏好和特征）
```

#### 记忆淘汰策略

**时间衰减**：越老的记忆权重越低
```python
def calculate_memory_relevance(memory, days_decay=30):
    """计算记忆的相关性分数"""
    import time
    days_old = (time.time() - memory['timestamp']) / 86400
    recency_score = math.exp(-days_old / days_decay)
    
    # 访问频率加成
    access_score = min(memory['access_count'] / 10, 1.0)
    
    return recency_score * 0.7 + access_score * 0.3
```

**重要性标记**：允许用户或系统标记重要记忆
```python
def add_important_memory(self, content, importance=1.0):
    """添加高优先级记忆"""
    self.collection.add(
        documents=[content],
        metadatas={
            "importance": importance,
            "never_expire": True
        }
    )
```

### 6. 实操案例：个人助理记忆系统

让我们构建一个完整的个人助理记忆系统：

```python
import json
from datetime import datetime
from typing import List, Dict, Optional

class PersonalAssistantMemory:
    """个人助理记忆系统"""
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.short_term = []  # 当前会话消息
        self.db = LongTermMemory()
        self.vector_db = VectorMemory()
    
    async def process_interaction(self, user_input: str, assistant_response: str):
        """处理一次交互，更新记忆"""
        # 1. 保存到短期记忆
        self.short_term.append({
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now().isoformat()
        })
        self.short_term.append({
            "role": "assistant", 
            "content": assistant_response,
            "timestamp": datetime.now().isoformat()
        })
        
        # 2. 提取关键事实
        await self._extract_facts(user_input, assistant_response)
        
        # 3. 检查是否需要生成会话摘要
        if len(self.short_term) >= 20:
            await self._archive_session()
    
    async def _extract_facts(self, user_msg: str, assistant_msg: str):
        """从对话中提取关键事实"""
        extraction_prompt = f"""
        从以下对话中提取关键事实（用户偏好、重要信息、决策等）。
        用JSON格式返回，如果没有则返回空数组。
        
        用户：{user_msg}
        助理：{assistant_msg}
        
        示例输出：["用户喜欢早上9点开始工作", "用户在开发一个AI项目"]
        """
        
        response = await llm.generate(extraction_prompt)
        try:
            facts = json.loads(response)
            for fact in facts:
                self.vector_db.add_memory(self.user_id, fact, "fact")
        except:
            pass  # 解析失败则忽略
    
    async def _archive_session(self):
        """归档当前会话"""
        # 生成会话摘要
        summary_prompt = f"""
        总结以下对话的关键信息和用户偏好变化：
        {json.dumps(self.short_term, ensure_ascii=False)}
        """
        summary = await llm.generate(summary_prompt)
        
        # 保存到长期记忆
        self.db.conn.execute(
            "INSERT INTO conversation_history (user_id, session_id, summary) VALUES (?, ?, ?)",
            (self.user_id, datetime.now().isoformat(), summary)
        )
        self.db.conn.commit()
        
        # 清空短期记忆，保留摘要
        self.short_term = [{"role": "system", "content": f"历史摘要：{summary}"}]
    
    def get_context_for_prompt(self, current_query: str) -> List[Dict]:
        """构建用于提示的上下文"""
        context = []
        
        # 1. 添加系统提示
        context.append({
            "role": "system",
            "content": f"你是用户的个人助理。以下是关于用户的已知信息："
        })
        
        # 2. 检索相关长期记忆
        relevant_memories = self.vector_db.search_relevant_memories(
            self.user_id, current_query, n_results=5
        )
        if relevant_memories:
            context.append({
                "role": "system",
                "content": "相关背景：\n" + "\n".join(relevant_memories)
            })
        
        # 3. 添加短期记忆
        context.extend(self.short_term[-10:])  # 最近10条
        
        return context
```

### 7. 隐私保护

记忆系统涉及大量用户数据，隐私保护至关重要：

#### 数据安全措施

1. **数据加密**：敏感记忆加密存储
```python
from cryptography.fernet import Fernet

class EncryptedMemory:
    def __init__(self, key):
        self.cipher = Fernet(key)
    
    def store(self, data):
        encrypted = self.cipher.encrypt(data.encode())
        return encrypted
    
    def retrieve(self, encrypted_data):
        decrypted = self.cipher.decrypt(encrypted_data)
        return decrypted.decode()
```

2. **数据隔离**：每个用户的记忆严格隔离
3. **访问控制**：基于角色的权限管理
4. **数据保留策略**：定期清理过期记忆

#### 用户控制权

- **查看记忆**：用户应该能查看助手记住了什么
- **删除记忆**：提供"忘记"特定信息的功能
- **导出数据**：允许用户导出自己的记忆数据

```python
class MemoryPrivacy:
    def forget(self, user_id, query):
        """根据查询删除相关记忆"""
        memories = self.vector_db.search(query)
        for mem_id in memories:
            self.vector_db.delete(mem_id)
    
    def export_user_data(self, user_id):
        """导出用户所有记忆数据"""
        return {
            "preferences": self.db.get_preference(user_id),
            "memories": self.vector_db.get_all_user_memories(user_id),
            "history": self.db.get_conversation_history(user_id)
        }
```

### 8. 总结

智能体记忆系统的设计要点：

| 维度 | 短期记忆 | 长期记忆 |
|------|---------|---------|
| 存储位置 | 内存 | 数据库/向量存储 |
| 生命周期 | 会话级 | 持久化 |
| 访问速度 | 极快 | 较慢 |
| 主要用途 | 当前上下文 | 知识积累 |
| 实现复杂度 | 低 | 高 |

**最佳实践建议：**

1. **分层设计**：工作记忆 → 短期摘要 → 长期知识 → 核心画像
2. **自动提取**：利用LLM自动从对话中提取关键信息
3. **语义检索**：使用向量数据库存储和检索语义化记忆
4. **定期归档**：会话结束后生成摘要，释放短期记忆压力
5. **隐私优先**：加密敏感数据，给用户提供记忆控制权

记忆系统是智能体从"工具"进化为"伙伴"的关键。一个好的记忆系统能让智能体越用越懂用户，真正成为个人化的AI助手。

---

*本文由AI自动生成，每日更新AI技术教程。如有疑问欢迎留言交流！*

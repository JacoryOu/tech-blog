---
title: "RAGå…¥é—¨ï¼šè®©å¤§æ¨¡å‹æ‹¥æœ‰å¤–éƒ¨çŸ¥è¯†"
date: 2026-02-06 08:00:28
author: "å°æ¬§Jacory"
category: "AI"
tags: ["RAG", "LLM", "å‘é‡æ•°æ®åº“", "LangChain"]
readTime: 20
cover: ""
excerpt: "è¯¦è§£æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯åŸç†ã€ç³»ç»Ÿæ¶æ„å’Œå®Œæ•´å®ç°ï¼Œé€šè¿‡ä¼ä¸šçŸ¥è¯†åº“é—®ç­”æ¡ˆä¾‹ï¼Œå­¦ä¹ å¦‚ä½•è®©å¤§è¯­è¨€æ¨¡å‹è®¿é—®å’Œåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†ã€‚"
featured: false
---

## ç›®å½•

- [ä»€ä¹ˆæ˜¯RAG](#ä»€ä¹ˆæ˜¯rag)
- [ä¸ºä»€ä¹ˆéœ€è¦RAG](#ä¸ºä»€ä¹ˆéœ€è¦rag)
- [RAGå·¥ä½œåŸç†](#ragå·¥ä½œåŸç†)
- [ç³»ç»Ÿæ¶æ„è®¾è®¡](#ç³»ç»Ÿæ¶æ„è®¾è®¡)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [å®æ“æ¡ˆä¾‹ï¼šä¼ä¸šçŸ¥è¯†åº“é—®ç­”](#å®æ“æ¡ˆä¾‹ä¼ä¸šçŸ¥è¯†åº“é—®ç­”)
- [ä¼˜åŒ–æŠ€å·§](#ä¼˜åŒ–æŠ€å·§)
- [æ€»ç»“](#æ€»ç»“)

## ä»€ä¹ˆæ˜¯RAG

**RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰** æ˜¯ä¸€ç§å°†å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä¸å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆèƒ½åŠ›ç›¸ç»“åˆçš„æŠ€æœ¯æ¶æ„ã€‚

ä¼ ç»Ÿçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4ã€Claudeç­‰ï¼‰è™½ç„¶å…·å¤‡å¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œä½†å­˜åœ¨ä¸¤ä¸ªæ ¸å¿ƒå±€é™ï¼š

1. **çŸ¥è¯†æˆªæ­¢æ—¥æœŸ**ï¼šæ¨¡å‹çš„è®­ç»ƒæ•°æ®æœ‰æ˜ç¡®çš„æ—¶é—´ cutoffï¼Œæ— æ³•è·å–æœ€æ–°ä¿¡æ¯
2. **å¹»è§‰é—®é¢˜**ï¼šæ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆå¬èµ·æ¥åˆç†ä½†å®é™…é”™è¯¯çš„å†…å®¹

RAG é€šè¿‡å¼•å…¥å¤–éƒ¨çŸ¥è¯†åº“ï¼Œè®©æ¨¡å‹åœ¨å›ç­”é—®é¢˜å‰å…ˆæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ŒåŸºäºæ£€ç´¢åˆ°çš„å‡†ç¡®ä¿¡æ¯æ¥ç”Ÿæˆå›ç­”ï¼Œä»è€Œè§£å†³ä¸Šè¿°é—®é¢˜ã€‚

### RAG çš„æ ¸å¿ƒä»·å€¼

| èƒ½åŠ› | ä¼ ç»ŸLLM | RAGå¢å¼º |
|------|---------|---------|
| æœ€æ–°çŸ¥è¯† | âŒ å—é™äºè®­ç»ƒæ•°æ® | âœ… å¯å®æ—¶æ›´æ–°çŸ¥è¯†åº“ |
| å‡†ç¡®æ€§ | âš ï¸ å¯èƒ½äº§ç”Ÿå¹»è§‰ | âœ… åŸºäºæ£€ç´¢äº‹å®ç”Ÿæˆ |
| å¯æº¯æº | âŒ æ— æ³•çŸ¥é“æ¥æº | âœ… å¯å±•ç¤ºå‚è€ƒæ–‡æ¡£ |
| ç§æœ‰åŒ– | âŒ éœ€è¦è®­ç»ƒ | âœ… ç›´æ¥æŒ‚è½½ç§æœ‰æ–‡æ¡£ |

## ä¸ºä»€ä¹ˆéœ€è¦RAG

### åœºæ™¯1ï¼šä¼ä¸šçŸ¥è¯†åº“é—®ç­”

æƒ³è±¡ä¸€ä¸ªå®¢æœåœºæ™¯ï¼šç”¨æˆ·è¯¢é—®"å…¬å¸2024å¹´çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ"

- **ä¼ ç»ŸLLM**ï¼šå¯èƒ½åŸºäºè¿‡æ—¶çš„è®­ç»ƒæ•°æ®å›ç­”ï¼Œæˆ–è€…ç¼–é€ æ”¿ç­–
- **RAGæ–¹æ¡ˆ**ï¼šä»ä¼ä¸šæœ€æ–°çš„æ”¿ç­–æ–‡æ¡£ä¸­æ£€ç´¢å‡†ç¡®ä¿¡æ¯ï¼Œç»™å‡ºæƒå¨å›ç­”

### åœºæ™¯2ï¼šåŒ»å­¦æ–‡çŒ®æŸ¥è¯¢

åŒ»ç”Ÿè¯¢é—®æŸç§ç½•è§ç—…çš„æœ€æ–°æ²»ç–—æ–¹æ¡ˆã€‚

- **ä¼ ç»ŸLLM**ï¼šè®­ç»ƒæ•°æ®å¯èƒ½ä¸åŒ…å«æœ€æ–°åŒ»å­¦ç ”ç©¶
- **RAGæ–¹æ¡ˆ**ï¼šä»PubMedç­‰æœ€æ–°è®ºæ–‡åº“æ£€ç´¢ç›¸å…³ç ”ç©¶

### åœºæ™¯3ï¼šæ³•å¾‹æ³•è§„å’¨è¯¢

æŸ¥è¯¢æœ€æ–°çš„ç¨æ³•å˜æ›´ã€‚

- **ä¼ ç»ŸLLM**ï¼šæ— æ³•è·çŸ¥æœ€æ–°æ³•å¾‹ä¿®è®¢
- **RAGæ–¹æ¡ˆ**ï¼šè¿æ¥å®˜æ–¹æ³•å¾‹æ•°æ®åº“ï¼Œæä¾›å‡†ç¡®æ¡æ–‡

## RAGå·¥ä½œåŸç†

RAG ç³»ç»Ÿçš„å·¥ä½œæµç¨‹å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š

### é˜¶æ®µ1ï¼šæ–‡æ¡£é¢„å¤„ç†ï¼ˆç¦»çº¿ï¼‰

```
åŸå§‹æ–‡æ¡£ â†’ æ–‡æœ¬æå– â†’ æ–‡æœ¬åˆ†å— â†’ å‘é‡åŒ– â†’ å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
```

1. **æ–‡æœ¬æå–**ï¼šä»PDFã€Wordã€ç½‘é¡µç­‰æ ¼å¼æå–çº¯æ–‡æœ¬
2. **æ–‡æœ¬åˆ†å—**ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆé€‚å½“å¤§å°çš„æ®µè½ï¼ˆé€šå¸¸500-1000å­—ç¬¦ï¼‰
3. **å‘é‡åŒ–**ï¼šä½¿ç”¨Embeddingæ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
4. **å­˜å‚¨**ï¼šå°†å‘é‡å­˜å…¥å‘é‡æ•°æ®åº“ï¼ˆå¦‚Chromaã€Pineconeã€Milvusï¼‰

### é˜¶æ®µ2ï¼šæ£€ç´¢ï¼ˆåœ¨çº¿ï¼‰

```
ç”¨æˆ·é—®é¢˜ â†’ å‘é‡åŒ– â†’ ç›¸ä¼¼åº¦æœç´¢ â†’ è¿”å›Top-Kç›¸å…³æ–‡æ¡£
```

1. å°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºå‘é‡
2. åœ¨å‘é‡æ•°æ®åº“ä¸­è¿›è¡Œç›¸ä¼¼åº¦æœç´¢
3. è¿”å›æœ€ç›¸å…³çš„Kä¸ªæ–‡æ¡£ç‰‡æ®µ

### é˜¶æ®µ3ï¼šç”Ÿæˆï¼ˆåœ¨çº¿ï¼‰

```
ç”¨æˆ·é—®é¢˜ + æ£€ç´¢åˆ°çš„æ–‡æ¡£ â†’ æ„å»ºPrompt â†’ LLMç”Ÿæˆå›ç­”
```

å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·é€å…¥å¤§æ¨¡å‹ï¼Œç”ŸæˆåŸºäºäº‹å®çš„å›ç­”ã€‚

## ç³»ç»Ÿæ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·æé—®      â”‚â”€â”€â”€â”€â–¶â”‚   é—®é¢˜å‘é‡åŒ–    â”‚â”€â”€â”€â”€â–¶â”‚  å‘é‡ç›¸ä¼¼åº¦æœç´¢  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   å‘é‡æ•°æ®åº“     â”‚
                    â”‚  (ChromaDBç­‰)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å±•ç¤ºå›ç­”      â”‚â—€â”€â”€â”€â”€â”‚   LLMç”Ÿæˆå›ç­”   â”‚â—€â”€â”€â”€â”€â”‚  æ„å»ºPrompt     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–²
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ç¯å¢ƒå‡†å¤‡

### å®‰è£…ä¾èµ–

```bash
pip install langchain langchain-openai chromadb python-dotenv
```

### é…ç½®APIå¯†é’¥

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### å‡†å¤‡æµ‹è¯•æ–‡æ¡£

åˆ›å»ºä¸€ä¸ª `docs/company_policy.txt`ï¼š

```
å…¬å¸é€€è´§æ”¿ç­–ï¼ˆ2024å¹´æ›´æ–°ï¼‰ï¼š

1. æ— ç†ç”±é€€è´§ï¼šè‡ªè´­ä¹°ä¹‹æ—¥èµ·7å¤©å†…å¯ç”³è¯·æ— ç†ç”±é€€è´§
2. è´¨é‡é—®é¢˜é€€è´§ï¼šå‘ç°è´¨é‡é—®é¢˜å¯åœ¨30å¤©å†…ç”³è¯·é€€è´§
3. é€€è´§æµç¨‹ï¼š
   - ç™»å½•å®˜ç½‘æäº¤é€€è´§ç”³è¯·
   - å®¢æœå®¡æ ¸é€šè¿‡åå¯„å›å•†å“
   - ä»“åº“éªŒæ”¶å3ä¸ªå·¥ä½œæ—¥å†…é€€æ¬¾
4. ç‰¹æ®Šå•†å“ï¼šå®šåˆ¶ç±»å•†å“ä¸æ”¯æŒé€€è´§
```

## å®æ“æ¡ˆä¾‹ï¼šä¼ä¸šçŸ¥è¯†åº“é—®ç­”

### å®Œæ•´ä»£ç å®ç°

```python
import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# 1. å‡†å¤‡æ–‡æ¡£
def load_documents():
    """åŠ è½½æ–‡æ¡£å¹¶åˆ†å‰²æˆå—"""
    # è¯»å–æ–‡æ¡£
    with open('docs/company_policy.txt', 'r', encoding='utf-8') as f:
        text = f.read()
    
    # æ–‡æœ¬åˆ†å‰²
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=200,
        chunk_overlap=50,
        length_function=len
    )
    
    chunks = text_splitter.split_text(text)
    return chunks

# 2. åˆ›å»ºå‘é‡æ•°æ®åº“
def create_vector_store(chunks):
    """åˆ›å»ºå‘é‡æ•°æ®åº“"""
    # ä½¿ç”¨OpenAIçš„Embeddingæ¨¡å‹
    embeddings = OpenAIEmbeddings()
    
    # åˆ›å»ºChromaå‘é‡æ•°æ®åº“
    vector_store = Chroma.from_texts(
        texts=chunks,
        embedding=embeddings,
        persist_directory="./chroma_db"
    )
    
    # æŒä¹…åŒ–å­˜å‚¨
    vector_store.persist()
    return vector_store

# 3. æ„å»ºRAGé—®ç­”é“¾
def create_qa_chain(vector_store):
    """åˆ›å»ºé—®ç­”é“¾"""
    # åˆå§‹åŒ–LLM
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0
    )
    
    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = vector_store.as_retriever(
        search_kwargs={"k": 2}  # è¿”å›æœ€ç›¸å…³çš„2ä¸ªæ–‡æ¡£
    )
    
    # æ„å»ºRAGé“¾
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True  # è¿”å›å‚è€ƒæ–‡æ¡£
    )
    
    return qa_chain

# 4. ä¸»ç¨‹åº
def main():
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
    
    # åŠ è½½æ–‡æ¡£
    chunks = load_documents()
    print(f"âœ… æ–‡æ¡£å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªç‰‡æ®µ")
    
    # åˆ›å»ºå‘é‡æ•°æ®åº“
    vector_store = create_vector_store(chunks)
    print("âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºé—®ç­”é“¾
    qa_chain = create_qa_chain(vector_store)
    print("âœ… RAGé—®ç­”é“¾å·²å°±ç»ª\n")
    
    # äº¤äº’å¼é—®ç­”
    while True:
        question = input("\nğŸ“ è¯·è¾“å…¥é—®é¢˜ (è¾“å…¥'quit'é€€å‡º): ")
        
        if question.lower() == 'quit':
            break
        
        # æ‰§è¡Œé—®ç­”
        result = qa_chain.invoke({"query": question})
        
        print("\n" + "="*50)
        print(f"ğŸ¤– å›ç­”:\n{result['result']}")
        print("="*50)
        
        # æ˜¾ç¤ºå‚è€ƒæ¥æº
        if result.get('source_documents'):
            print("\nğŸ“š å‚è€ƒæ¥æº:")
            for i, doc in enumerate(result['source_documents'], 1):
                print(f"  [{i}] {doc.page_content[:100]}...")

if __name__ == "__main__":
    main()
```

### è¿è¡Œæµ‹è¯•

```bash
python rag_demo.py
```

ç¤ºä¾‹äº¤äº’ï¼š

```
ğŸš€ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...
âœ… æ–‡æ¡£å·²åˆ†å‰²ä¸º 3 ä¸ªç‰‡æ®µ
âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ
âœ… RAGé—®ç­”é“¾å·²å°±ç»ª

ğŸ“ è¯·è¾“å…¥é—®é¢˜ (è¾“å…¥'quit'é€€å‡º): é€€è´§æœŸé™æ˜¯å¤šä¹…ï¼Ÿ

==================================================
ğŸ¤– å›ç­”:
æ ¹æ®å…¬å¸é€€è´§æ”¿ç­–ï¼Œé€€è´§æœŸé™åˆ†ä¸ºä¸¤ç§æƒ…å†µï¼š
1. æ— ç†ç”±é€€è´§ï¼šè‡ªè´­ä¹°ä¹‹æ—¥èµ·7å¤©å†…å¯ç”³è¯·
2. è´¨é‡é—®é¢˜é€€è´§ï¼šå¯åœ¨30å¤©å†…ç”³è¯·é€€è´§
==================================================

ğŸ“š å‚è€ƒæ¥æº:
  [1] å…¬å¸é€€è´§æ”¿ç­–ï¼ˆ2024å¹´æ›´æ–°ï¼‰ï¼š1. æ— ç†ç”±é€€è´§ï¼šè‡ªè´­ä¹°ä¹‹æ—¥èµ·7å¤©å†…å¯ç”³è¯·æ— ç†ç”±é€€è´§...
  [2] 2. è´¨é‡é—®é¢˜é€€è´§ï¼šå‘ç°è´¨é‡é—®é¢˜å¯åœ¨30å¤©å†…ç”³è¯·é€€è´§...
```

## ä¼˜åŒ–æŠ€å·§

### 1. æ–‡æœ¬åˆ†å—ç­–ç•¥

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# é€’å½’åˆ†å—ï¼Œæ›´æ™ºèƒ½
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100,
    separators=["\n\n", "\n", "ã€‚", " ", ""]
)
```

### 2. æ··åˆæ£€ç´¢

ç»“åˆå…³é”®è¯æ£€ç´¢å’Œå‘é‡æ£€ç´¢ï¼š

```python
from langchain.retrievers import BM25Retriever, EnsembleRetriever

# BM25å…³é”®è¯æ£€ç´¢
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 2

# å‘é‡æ£€ç´¢
vector_retriever = vector_store.as_retriever(search_kwargs={"k": 2})

# æ··åˆæ£€ç´¢ï¼ˆæƒé‡å¯è°ƒæ•´ï¼‰
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.5, 0.5]
)
```

### 3. é‡æ’åºä¼˜åŒ–

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

# ä½¿ç”¨LLMå¯¹æ£€ç´¢ç»“æœé‡æ–°æ’åº
compressor = LLMChainExtractor.from_llm(llm)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=retriever
)
```

### 4. æç¤ºè¯å·¥ç¨‹

```python
from langchain.prompts import PromptTemplate

custom_prompt = """åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ä¸”å‡†ç¡®çš„å›ç­”ï¼š"""

PROMPT = PromptTemplate(
    template=custom_prompt,
    input_variables=["context", "question"]
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": PROMPT}
)
```

## æ€»ç»“

æœ¬ç¯‡æ–‡ç« è¯¦ç»†ä»‹ç»äº† **RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰** æŠ€æœ¯çš„æ ¸å¿ƒæ¦‚å¿µã€å·¥ä½œåŸç†å’Œå®è·µæ–¹æ³•ã€‚

### é‡ç‚¹å›é¡¾

| è¦ç‚¹ | è¯´æ˜ |
|------|------|
| **ä»€ä¹ˆæ˜¯RAG** | å°†å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä¸LLMç”Ÿæˆç›¸ç»“åˆçš„æŠ€æœ¯æ¶æ„ |
| **ä¸ºä»€ä¹ˆéœ€è¦** | è§£å†³LLMçŸ¥è¯†æˆªæ­¢å’Œå¹»è§‰é—®é¢˜ |
| **å·¥ä½œåŸç†** | æ–‡æ¡£é¢„å¤„ç† â†’ å‘é‡åŒ–å­˜å‚¨ â†’ ç›¸ä¼¼åº¦æ£€ç´¢ â†’ ä¸Šä¸‹æ–‡ç”Ÿæˆ |
| **æ ¸å¿ƒç»„ä»¶** | Embeddingæ¨¡å‹ã€å‘é‡æ•°æ®åº“ã€LLMã€æ£€ç´¢å™¨ |

### è¿›é˜¶æ–¹å‘

1. **å¤šæ¨¡æ€RAG**ï¼šæ”¯æŒå›¾ç‰‡ã€PDFã€è¡¨æ ¼ç­‰å¤šç§æ–‡æ¡£ç±»å‹
2. **Agentic RAG**ï¼šè®©RAGå…·å¤‡è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œå¯å¤šæ¬¡æ£€ç´¢
3. **Graph RAG**ï¼šç»“åˆçŸ¥è¯†å›¾è°±è¿›è¡Œæ›´å¤æ‚çš„æ¨ç†
4. **æœ¬åœ°éƒ¨ç½²**ï¼šä½¿ç”¨Ollamaç­‰å·¥å…·å®ç°å®Œå…¨ç§æœ‰åŒ–

---

*æœ¬æ–‡ç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œæ¯æ—¥æ›´æ–°AIæŠ€æœ¯æ•™ç¨‹ã€‚å¦‚æœ‰ç–‘é—®æ¬¢è¿ç•™è¨€äº¤æµï¼*